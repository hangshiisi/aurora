\documentclass[fontsize=11pt,paper=a4,pagesize=auto]{report}

\usepackage[english]{babel}
\usepackage{microtype}
\usepackage{blindtext}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{csquotes}


\lstset{
  language=C,
  basicstyle=\small,
  breaklines=true}
\frenchspacing 
\begin{document}

\begin{titlepage}
  \vspace*{1cm}
  {\huge\raggedright Report of Captone Project Task 1\par}
  \noindent\hrulefill\par
  {\LARGE\raggedleft A Student in Coursera\par}
  \vfill
  {\Large\raggedleft 10/31/2017\par}
\end{titlepage}

%\tableofcontents{}


\section{Overview}
This report covers the design and implementation details for Cloud Computing Captone Project Task 1. The goals of this task are to perform the following:
\begin{itemize}
\item Extract and clean the transportation dataset, and then store the result in HDFS.
\item Answer 2 questions from Group 1, 3 questions from Group 2, and both questions from Group 3 using Hadoop. Store the results for questions from Group 2 and Question 3.2 in Cassandra.   
\end{itemize}
 
\section{Data Cleanup}
\par The first task is to clean and store the dataset. We  first retrieve and extract the dataset from the EBS volume snapshot by following steps in \url{http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-restoring-volume.html}. One key thing to note is that we need to create EC2 instance in the same region and availabbility zone as the data EBS snapshot (snap-e1608d88 in us-east-1d).   
\par Afterwards, we explore the data set and decide on how we wish to clean it. Then we ignore unrelated rows and extract only the columns from the csv files. The raw data is in \path{/data/aviation/airline_ontime} directory. 
\par Approaches: Two ways have been used to do the cleanup: 
\begin{itemize} 
\item A python script is developed on top of \href{https://docs.python.org/2/library/csv.html}{python CSV package} to achieve this. 
\item Pig script, see \url{https://pig.apache.org/} for details. 
\end{itemize}

\par Such data cleanup is a one-time job and below are the fields we extracted: 
\begin{itemize}
\item       AirlineID:chararray, --a8
\item       Carrier:chararray,   --a9
\item       FlightNum:int,       --a11
\item       Origin:chararray,    --a12       
\item       Dest:chararray,      --a18
\item       DepDelay:float,      --a26
\item       DepDel15:float,      --a28
\item       ArrDelay:float,      --a37 
\item       ArrDel15:float       --a39
\end{itemize}

\par The cleaned data are stored on HDFS via below hdfs dfs command  as tab delimetered fields with each line indicating one flight. 
\begin{lstlisting}{centered}
	hdfs dfs -copyFromLocal <local files> <hdfs dir>  
\end{lstlisting}
 
\section{System Overview}
\subsection{Hadoop MapReduce}
The system is essentially a 4 node Apache Hadoop cluster with one namenode and three datanodes running on AWS EC2. 
Hadoop Yarn runs and serves as the resource manager and application manager.

\subsection{Cassandra} 
Cassandra cluster is deployed on the three Hadoop datanodes to provide data replication and scalability. 
The cluster run on the same rack and utilizes GossipingPropertyFileSnitch scheme. One of the nodes is assigned as the seed provider.
 
\section{Group 1 Problems} 

\begin{itemize} 
\item Problem 1.1: Rank the top 10 most popular airports by numbers of flights to/from the airport.
Solution: We extracted the origin and destination city of the flight for each line of the cleaned files. It is done two steps: counting via map and reduce phases in Hadoop and sort to get top 10 airports. In the map phase, we generate pairs (origin, 1) and (dest, 1). In the reduce phase, if we see a new airport, we output the airport and count; if we see same airport, we add the count to existing counter. Once the counters are outputted, below commands can be used to get top airports (use 20 to allow duplicated top cases). 
\begin{lstlisting}[language = C++]
hadoop fs -cat /output/of/wordcount/part* | sort -n -k2 -r | head -n20
\end{lstlisting}
Alternatively, the top N problem can be solved via \href{https://github.com/adamjshook/mapreducepatterns/blob/master/MRDP/src/main/java/mrdp/ch3/TopTenDriver.java}{this MapReduce design pattern}. 

\item Problem 1.2: Rank the top 10 airlines by on-time arrival performance
In the map phase, we generate (airline, 1, delay). In the reduce phase, we use two maps: (airline, count), and (airline, total delay) and accumulate counter and delay into these two maps. Then we calculate arrival performance and sort them. Alternatively and if there are multiple reducers, we will use commands similar as in above problem to do sorting. 

\item Problem 1.3: Rank the days of the week by on-time arrival performance
This is a similar problem as Problem 1.2. We use (weekday, delay) as input data. In the map phase, we generate (weekday, 1, delay). In the reduce phase, we use two maps: (weekday, count), and (weekday, total delay) and accumulate counter and delay into these two maps. Then we calculate arrival performance and sort them.   

\end{itemize}
 
\section{Group 2 Problems}
 
 For each airport X, rank the top-10 carriers in decreasing order of on-time departure performance from X.
For each airport X, rank the top-10 airports in decreasing order of on-time departure performance from X.
For each source-destination pair X-Y, rank the top-10 carriers in decreasing order of on-time arrival performance at Y from X.
For each source-destination pair X-Y, determine the mean arrival delay (in minutes) for a flight from X to Y.


\blindtext

\section{Group 3 Problems}
 

\blindtext

\section{Optimization Techniques}
 

\blindtext
 
\section{Result Measurement}
Correctness 

Speed 

Video clearly shows both of the following: 1) Ingesting and analyzing data in the systems; 2) Querying results.


 
\end{document}

